{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c37e98",
   "metadata": {},
   "source": [
    "## Feed-forward Neural Network with MLP (Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8ae539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def passthru(x):\n",
    "    return x\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "class NeuralNetwork():\n",
    "\n",
    "    def __init__(self, input_dim=1,\n",
    "                 output_dim=24,\n",
    "                 units=[20,20,20],\n",
    "                 activations=[\"relu\", \"relu\", \"relu\", \"passthru\"]):\n",
    "        if activations[-1] != \"passthru\":\n",
    "            raise ValueError(\"output activation must be passthru\")\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.units = units\n",
    "        self.num_layers = len(units)\n",
    "        \n",
    "        self.activations = []\n",
    "        for act in activations:\n",
    "            if act == \"relu\":\n",
    "                self.activations += [relu]\n",
    "            elif act == \"passthru\":\n",
    "                self.activations += [passthru]\n",
    "            else:\n",
    "                self.activations += [tanh]\n",
    "    \n",
    "        unit_list = [input_dim]\n",
    "        for u in self.units:\n",
    "            unit_list += [u, u]\n",
    "        unit_list += [output_dim]\n",
    "        self.shapes = []\n",
    "        for l in range(self.num_layers+1):\n",
    "            self.shapes += [(unit_list[2*l], unit_list[2*l+1])]\n",
    "        \n",
    "        self.weight = []\n",
    "        self.bias = []\n",
    "        self.parameter_count = 0\n",
    "        idx = 0\n",
    "        for shape in self.shapes:\n",
    "            self.weight.append(np.zeros(shape=shape))\t\n",
    "            self.bias.append(np.zeros(shape=shape[1]))\n",
    "            self.parameter_count += (np.product(shape) + shape[1])\n",
    "            idx += 1\n",
    "\n",
    "    def set_weights(self, model_params):\n",
    "        pointer = 0\n",
    "        for i in range(len(self.shapes)):\n",
    "            w_shape = self.shapes[i]\n",
    "            b_shape = self.shapes[i][1]\n",
    "            s_w = np.product(w_shape)\n",
    "            s = s_w + b_shape\n",
    "            chunk = np.array(model_params[pointer:pointer+s])\n",
    "            self.weight[i] = chunk[:s_w].reshape(w_shape)\n",
    "            self.bias[i] = chunk[s_w:].reshape(b_shape)\n",
    "            pointer += s\n",
    "\n",
    "    def predict(self, X):\n",
    "        h = np.array([X]).flatten()\n",
    "        num_layers= len(self.weight)\n",
    "        for i in range(num_layers):\n",
    "            w = self.weight[i]\n",
    "            b = self.bias[i]\n",
    "            h = np.matmul(h, w) + b\n",
    "            h = self.activations[i](h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a76994ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.]\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork(input_dim=5, output_dim=1, units=[5], activations=[\"relu\",\"passthru\"])\n",
    "params = np.ones(NN.parameter_count)\n",
    "NN.set_weights(params)\n",
    "print (NN.predict(np.ones(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cb5dad",
   "metadata": {},
   "source": [
    "## Feed-forward Neural Network with MLP (Torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2d9e771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch_nn = nn.Sequential(\n",
    "    nn.Linear(5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "for module in torch_nn:\n",
    "    if hasattr(module, 'weight'):  # Check if the module has the 'weight' attribute\n",
    "        with torch.no_grad():  # Disable gradient tracking\n",
    "            module.weight = nn.Parameter(torch.ones_like(module.weight))\n",
    "            if module.bias is not None:\n",
    "                module.bias = nn.Parameter(torch.ones_like(module.bias))\n",
    "\n",
    "torch_nn.forward(torch.from_numpy(np.ones(5)).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c82839",
   "metadata": {},
   "source": [
    "## Feed-forward Neural Network with MLP (Torch): Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75faa072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b06f69dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.3052\n",
      "Epoch [20/100], Loss: 0.6348\n",
      "Epoch [30/100], Loss: 0.7402\n",
      "Epoch [40/100], Loss: 0.1647\n",
      "Epoch [50/100], Loss: 0.0146\n",
      "Epoch [60/100], Loss: 0.2996\n",
      "Epoch [70/100], Loss: 0.0322\n",
      "Epoch [80/100], Loss: 0.0577\n",
      "Epoch [90/100], Loss: 0.0360\n",
      "Epoch [100/100], Loss: 0.0593\n"
     ]
    }
   ],
   "source": [
    "# Synthetic dataset: y = 3*x + 2 + noise\n",
    "x = torch.randn(100, 1)  # 100 data points\n",
    "y = 3 * x + 2 + 0.1 * torch.randn(100, 1)  # True function with some noise\n",
    "\n",
    "# Dataset and DataLoader for mini-batch processing\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "dataset = TensorDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 20),  # Input features size is 1, output size is 20\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)  # Final layer outputting one value for regression\n",
    ")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs (iterations over the entire dataset)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()  # Clear existing gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update parameters\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
